{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m pageviews_element \u001b[39m=\u001b[39m soup\u001b[39m.\u001b[39mfind(\u001b[39m\"\u001b[39m\u001b[39mdiv\u001b[39m\u001b[39m\"\u001b[39m, class_\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mstMarkdown\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     18\u001b[0m \u001b[39m# Extraer el número de Pageviews\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m pageviews \u001b[39m=\u001b[39m pageviews_element\u001b[39m.\u001b[39;49mtext\u001b[39m.\u001b[39mstrip()  \u001b[39m# Puede requerir ajustes según la estructura del HTML\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[39m# Imprimir el número de Pageviews\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mPageviews:\u001b[39m\u001b[39m\"\u001b[39m, pageviews)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL de la página web a la que deseas hacer scraping\n",
    "url = \"https://pruebapy-gyappunpnnvudpj3pmwndbf.streamlit.app/?analytics=on\"\n",
    "\n",
    "# Realizar una solicitud GET para obtener el contenido de la página\n",
    "response = requests.get(url)\n",
    "\n",
    "# Comprobar si la solicitud fue exitosa\n",
    "if response.status_code == 200:\n",
    "    # Parsear el contenido HTML con BeautifulSoup\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    # Buscar el elemento que contiene el número de Pageviews\n",
    "    pageviews_element = soup.find(\"div\", class_=\"stMarkdown\")\n",
    "    \n",
    "    # Extraer el número de Pageviews\n",
    "    pageviews = pageviews_element.text.strip()  # Puede requerir ajustes según la estructura del HTML\n",
    "\n",
    "    # Imprimir el número de Pageviews\n",
    "    print(\"Pageviews:\", pageviews)\n",
    "else:\n",
    "    print(\"Error al obtener la página:\", response.status_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Tu fragmento de HTML\n",
    "html = \"\"\"\n",
    "<div data-testid=\"column\" class=\"css-1r6slb0 e1f1d6gn1\" style=\"position: relative;\">\n",
    "    <!-- ... (el HTML completo) ... -->\n",
    "    <div data-testid=\"stMetricValue\" class=\"css-1xarl3l e1i5pmia1\">\n",
    "        <div class=\"css-1wivap2 e1i5pmia3\"> 2 </div>\n",
    "    </div>\n",
    "    <!-- ... (más HTML) ... -->\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "# Crear un objeto BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# Encontrar el elemento que contiene el número de Pageviews\n",
    "pageviews_element = soup.find('div', class_='css-1xarl3l e1i5pmia1')\n",
    "\n",
    "# Extraer el número de Pageviews\n",
    "pageviews = pageviews_element.text.strip()\n",
    "\n",
    "# Imprimir el número de Pageviews\n",
    "print(\"Pageviews:\", pageviews)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elemento no encontrado en la página.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL de la página que deseas scrapear\n",
    "url = \"https://pruebapy-gyappunpnnvudpj3pmwndbf.streamlit.app/?analytics=on\"\n",
    "\n",
    "# Obtener el contenido HTML de la página\n",
    "response = requests.get(url)\n",
    "\n",
    "# Verificar si la solicitud fue exitosa (código de respuesta 200)\n",
    "if response.status_code == 200:\n",
    "    # Obtener el contenido HTML\n",
    "    html = response.text\n",
    "\n",
    "    # Crear un objeto BeautifulSoup\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    # Ahora puedes continuar con el código para extraer la información deseada.\n",
    "    # Por ejemplo, para extraer el número de Pageviews:\n",
    "    pageviews_element = soup.find('div', class_='css-1wivap2 e1i5pmia3')\n",
    "    if pageviews_element:\n",
    "        pageviews = pageviews_element.text.strip()\n",
    "        print(\"Pageviews:\", pageviews)\n",
    "    else:\n",
    "        print(\"Elemento no encontrado en la página.\")\n",
    "\n",
    "else:\n",
    "    print(\"Error al acceder a la página. Código de respuesta:\", response.status_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elemento principal no encontrado en el HTML.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL de la página web\n",
    "url = \"https://pruebapy-gyappunpnnvudpj3pmwndbf.streamlit.app/?analytics=on\"\n",
    "\n",
    "# Realizar una solicitud GET a la página web\n",
    "response = requests.get(url)\n",
    "\n",
    "# Obtener el contenido HTML de la página\n",
    "html = response.text\n",
    "\n",
    "# Parsear el HTML\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# Encontrar el elemento que contiene el número\n",
    "element = soup.find(\"div\", {\"class\": \"css-1xarl3l e1i5pmia1\"})\n",
    "if element:\n",
    "    # Encontrar el elemento que contiene el número dentro del elemento anterior\n",
    "    number_element = element.find(\"div\", {\"class\": \"css-1wivap2 e1i5pmia3\"})\n",
    "    if number_element:\n",
    "        # Extraer el número\n",
    "        pageviews = number_element.get_text(strip=True)\n",
    "        print(\"Pageviews:\", pageviews)\n",
    "    else:\n",
    "        print(\"Elemento de número no encontrado en el elemento principal.\")\n",
    "else:\n",
    "    print(\"Elemento principal no encontrado en el HTML.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elemento no encontrado en la página web.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL de la página web\n",
    "url = \"https://pruebapy-gyappunpnnvudpj3pmwndbf.streamlit.app/?analytics=on\"\n",
    "\n",
    "# Realizar una solicitud GET a la página web\n",
    "response = requests.get(url)\n",
    "\n",
    "# Obtener el contenido HTML de la página\n",
    "html = response.text\n",
    "\n",
    "# Comprobamos que la petición nos devuelve un Status Code = 200\n",
    "status_code = req.status_code\n",
    "if status_code == 200:\n",
    "\n",
    "    # Pasamos el contenido HTML de la web a un objeto BeautifulSoup()\n",
    "    html = BeautifulSoup(req.text, \"html.parser\")\n",
    "\n",
    "    # Obtenemos todos los divs donde están las entradas\n",
    "    entradas = html.find_all('div', {'class': 'col-md-4 col-xs-12'})\n",
    "\n",
    "    # Recorremos todas las entradas para extraer el título, autor y fecha\n",
    "    for i, entrada in enumerate(entradas):\n",
    "        # Con el método \"getText()\" no nos devuelve el HTML\n",
    "        titulo = entrada.find('span', {'class': 'tituloPost'}).getText()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "ResultSet object has no attribute 'getText'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m     html \u001b[39m=\u001b[39m BeautifulSoup(req\u001b[39m.\u001b[39mtext, \u001b[39m\"\u001b[39m\u001b[39mhtml.parser\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     16\u001b[0m     \u001b[39m# Obtenemos todos los divs donde están las entradas\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m     entradas \u001b[39m=\u001b[39m html\u001b[39m.\u001b[39;49mfind_all(\u001b[39m'\u001b[39;49m\u001b[39mdiv\u001b[39;49m\u001b[39m'\u001b[39;49m, {\u001b[39m'\u001b[39;49m\u001b[39mclass\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m'\u001b[39;49m\u001b[39mcss-1wivap2 e1i5pmia3\u001b[39;49m\u001b[39m'\u001b[39;49m})\u001b[39m.\u001b[39;49mgetText()\n\u001b[0;32m     18\u001b[0m     \u001b[39mprint\u001b[39m (entradas)\n\u001b[0;32m     19\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\nombre.apellido\\Desktop\\henry\\Lib\\site-packages\\bs4\\element.py:2428\u001b[0m, in \u001b[0;36mResultSet.__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2426\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getattr__\u001b[39m(\u001b[39mself\u001b[39m, key):\n\u001b[0;32m   2427\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Raise a helpful exception to explain a common code fix.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 2428\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[0;32m   2429\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mResultSet object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. You\u001b[39m\u001b[39m'\u001b[39m\u001b[39mre probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m key\n\u001b[0;32m   2430\u001b[0m     )\n",
      "\u001b[1;31mAttributeError\u001b[0m: ResultSet object has no attribute 'getText'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "URL = \"https://pruebapy-gyappunpnnvudpj3pmwndbf.streamlit.app/?analytics=on\"\n",
    "\n",
    "# Realizamos la petición a la web\n",
    "req = requests.get(URL)\n",
    "\n",
    "# Comprobamos que la petición nos devuelve un Status Code = 200\n",
    "status_code = req.status_code\n",
    "if status_code == 200:\n",
    "\n",
    "    # Pasamos el contenido HTML de la web a un objeto BeautifulSoup()\n",
    "    html = BeautifulSoup(req.text, \"html.parser\")\n",
    "\n",
    "    # Obtenemos todos los divs donde están las entradas\n",
    "    entradas = html.find_all('div', {'class': 'css-1wivap2 e1i5pmia3'})\n",
    "\n",
    "    # Recorremos todas las entradas para extraer el título, autor y fecha\n",
    "    for entrada in entradas:\n",
    "        # Con el método \"getText()\" no nos devuelve el HTML\n",
    "        titulo = entrada.find('div', {'class': 'css-1wivap2 e1i5pmia3'}).getText()\n",
    "\n",
    "        # Imprimo el Título, Autor y Fecha de las entradas\n",
    "        print (i + 1, titulo)\n",
    "\n",
    "else:\n",
    "    print (titulo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elemento principal de Pageviews no encontrado.\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "URL = \"https://pruebapy-gyappunpnnvudpj3pmwndbf.streamlit.app/?analytics=on\"\n",
    "\n",
    "# Realizamos la petición a la web\n",
    "req = requests.get(URL)\n",
    "\n",
    "# Comprobamos que la petición nos devuelve un Status Code = 200\n",
    "status_code = req.status_code\n",
    "if status_code == 200:\n",
    "\n",
    "    # Pasamos el contenido HTML de la web a un objeto BeautifulSoup()\n",
    "    html = BeautifulSoup(req.text, \"html.parser\")\n",
    "\n",
    "    # Obtenemos el div que contiene el número de Pageviews\n",
    "    pageviews_div = html.find('div', {'data-testid': 'stMetricValue'})\n",
    "\n",
    "    if pageviews_div:\n",
    "        # Encontramos el div dentro del div principal\n",
    "        numero_pageviews = pageviews_div.find('div', {'class': 'css-1wivap2 e1i5pmia3'})\n",
    "\n",
    "        if numero_pageviews:\n",
    "            # Obtenemos el número de Pageviews\n",
    "            pageviews = numero_pageviews.getText(strip=True)\n",
    "            print(\"Pageviews:\", pageviews)\n",
    "        else:\n",
    "            print(\"Elemento de número de Pageviews no encontrado.\")\n",
    "    else:\n",
    "        print(\"Elemento principal de Pageviews no encontrado.\")\n",
    "\n",
    "else:\n",
    "    print(\"La solicitud no tuvo éxito (Status Code:\", status_code, \")\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elemento principal de Pageviews no encontrado.\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "URL = \"https://pruebapy-gyappunpnnvudpj3pmwndbf.streamlit.app/?analytics=on\"\n",
    "\n",
    "# Realizamos la petición a la web\n",
    "req = requests.get(URL)\n",
    "\n",
    "# Comprobamos que la petición nos devuelve un Status Code = 200\n",
    "status_code = req.status_code\n",
    "if status_code == 200:\n",
    "\n",
    "    # Pasamos el contenido HTML de la web a un objeto BeautifulSoup()\n",
    "    html = BeautifulSoup(req.text, \"html.parser\")\n",
    "\n",
    "    # Obtenemos el div que contiene el número de Pageviews\n",
    "    pageviews_div = html.find('div', {'data-testid': 'stMetricValue'})\n",
    "\n",
    "    if pageviews_div:\n",
    "        # Encontramos el div dentro del div principal\n",
    "        numero_pageviews = pageviews_div.find('div', {'data-testid': 'stText'})\n",
    "\n",
    "        if numero_pageviews:\n",
    "            # Obtenemos el número de Pageviews\n",
    "            pageviews = numero_pageviews.getText(strip=True)\n",
    "            print(\"Pageviews:\", pageviews)\n",
    "        else:\n",
    "            print(\"Elemento de número de Pageviews no encontrado.\")\n",
    "    else:\n",
    "        print(\"Elemento principal de Pageviews no encontrado.\")\n",
    "\n",
    "else:\n",
    "    print(\"La solicitud no tuvo éxito (Status Code:\", status_code, \")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elemento no encontrado en la página.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL de la página web que deseas analizar\n",
    "url = \"https://pruebapy-gyappunpnnvudpj3pmwndbf.streamlit.app/?analytics=on\"\n",
    "\n",
    "# Realizar una solicitud GET a la página\n",
    "response = requests.get(url)\n",
    "\n",
    "# Verificar si la solicitud fue exitosa (código de estado 200)\n",
    "if response.status_code == 200:\n",
    "    # Obtener el contenido HTML de la página\n",
    "    html = response.text\n",
    "\n",
    "    # Parsear el HTML\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    # Encontrar el elemento que contiene la información deseada\n",
    "    pageviews_element = soup.find(\"div\", class_=\"css-1wivap2 e1i5pmia3\")\n",
    "\n",
    "    if pageviews_element:\n",
    "        # Extraer el número de Pageviews\n",
    "        pageviews = pageviews_element.text.strip()\n",
    "        print(\"Pageviews:\", pageviews)\n",
    "    else:\n",
    "        print(\"Elemento no encontrado en la página.\")\n",
    "else:\n",
    "    print(\"Error al hacer la solicitud a la página:\", response.status_code)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
